{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "kernelspec": {
      "name": "synapse_pyspark",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "python"
    },
    "save_output": true,
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Create a start schema and populate it with fake data\n",
        "\n",
        "we will use a retail scenario and create fake data for the start schema with following dimension tables: store, customer, product and the sollowing fact table: sales"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# install faker locally (session scoped) to generate fake data\n",
        "pip install faker faker-commerce"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Set the ADLS account name and the container name where the data will be generated in the data lake"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# make sure to create the following before you modify the variables below.\n",
        "\n",
        "# the ADLS account name, you could use your default ADLS account for this. \n",
        "# Please make sure that you have appropriate storage blob data contributor rights to this account\n",
        "adls_account_name=\"saanalyticstftest\"\n",
        "# The container where the generated data will be stored, you need to also create this\n",
        "adls_container_name=\"dataset\" "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "salesfact_path = \"abfss://{adls_fs_name}@{adls_account}.dfs.core.windows.net/salesfact\".format(adls_fs_name=adls_container_name, adls_account=adls_account_name)\n",
        "customerdim_path = \"abfss://{adls_fs_name}@{adls_account}.dfs.core.windows.net/customerdim\".format(adls_fs_name=adls_container_name, adls_account=adls_account_name)\n",
        "productdim_path = \"abfss://{adls_fs_name}@{adls_account}.dfs.core.windows.net/productdim\".format(adls_fs_name=adls_container_name, adls_account=adls_account_name)\n",
        "storedim_path = \"abfss://{adls_fs_name}@{adls_account}.dfs.core.windows.net/storedim\".format(adls_fs_name=adls_container_name, adls_account=adls_account_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "from pyspark.sql.types import StructType, StructField, IntegerType, DoubleType, StringType\r\n",
        "from pyspark.sql import functions as F\r\n",
        "from faker import Faker\r\n",
        "import faker_commerce\r\n",
        "import random\r\n",
        "\r\n",
        "fake = Faker()\r\n",
        "fake.add_provider(faker_commerce.Provider)\r\n",
        "salesfact_data = []\r\n",
        "customerdim_data = []\r\n",
        "productdim_data = []\r\n",
        "storedim_data = []\r\n",
        "\r\n",
        "# create 100 products, store their id/keys for sales later\r\n",
        "limit = 100\r\n",
        "product_key_price = {}\r\n",
        "for x in range(0, limit):\r\n",
        "    product_key = fake.hexify(text='^^^^^^^^^^^^')\r\n",
        "    product_name = fake.ecommerce_name()\r\n",
        "    product_base_price = round(random.uniform(1000.00, 100000.00), 2)\r\n",
        "\r\n",
        "    productdim_data.append( (product_key, product_name, product_base_price) )\r\n",
        "    product_key_price[product_key] = product_base_price\r\n",
        "\r\n",
        "# create 100 stores\r\n",
        "limit = 100\r\n",
        "for x in range(0, limit):\r\n",
        "    store_key = fake.hexify(text='^^^^^^^^^^^^')\r\n",
        "    store_city =  fake.city()\r\n",
        "    store_country = fake.country()\r\n",
        "\r\n",
        "    storedim_data.append(  (store_key, store_city, store_country) )\r\n",
        "    \r\n",
        "    # generate random 10-100 customers for each store\r\n",
        "    for x in range(0, fake.random_int(min=10, max=100)):\r\n",
        "        customer_key = fake.hexify(text='^^^^^^^^^^^^')\r\n",
        "        customer_city = store_city\r\n",
        "        customer_country = store_country\r\n",
        "        customer_name = fake.name()\r\n",
        "\r\n",
        "        customerdim_data.append( (customer_key, customer_city, customer_country, customer_name) )\r\n",
        "\r\n",
        "        # generate random sales between 10-100 for each customer  \r\n",
        "        for x in range(0, fake.random_int(min=1, max=10)):\r\n",
        "            salesfact_key = fake.hexify(text='^^^^^^^^^^^^')\r\n",
        "            product_key = fake.random_element(elements=product_key_price.keys())\r\n",
        "            sales_price = product_key_price.get(product_key) + round(random.uniform(100.00, 1000.00), 2)\r\n",
        "            sales_units = fake.random_int(min=1, max=7)\r\n",
        "            sales_month = fake.month_name()\r\n",
        "            sales_day = fake.day_of_month()\r\n",
        "            sales_year = fake.random_int(min=2010, max=2022)\r\n",
        "\r\n",
        "            salesfact_data.append( (salesfact_key, store_key, customer_key, product_key, sales_price, sales_units, sales_month, sales_day, sales_year) )\r\n",
        "            \r\n",
        "\r\n",
        "product_schema = StructType([       \r\n",
        "    StructField('product_key', StringType(), True),\r\n",
        "    StructField('product_name', StringType(), True),\r\n",
        "    StructField('product_base_price', DoubleType(), True)\r\n",
        "])\r\n",
        "\r\n",
        "store_schema = StructType([       \r\n",
        "    StructField('store_key', StringType(), True),\r\n",
        "    StructField('store_city', StringType(), True),\r\n",
        "    StructField('store_country', StringType(), True)\r\n",
        "])\r\n",
        "\r\n",
        "customer_schema = StructType([       \r\n",
        "    StructField('customer_key', StringType(), True),\r\n",
        "    StructField('customer_city', StringType(), True),\r\n",
        "    StructField('customer_country', StringType(), True),\r\n",
        "    StructField('customer_name', StringType(), True)\r\n",
        "])\r\n",
        "\r\n",
        "salesfact_schema = StructType([       \r\n",
        "    StructField('salesfact_key', StringType(), True),\r\n",
        "    StructField('store_key', StringType(), True),\r\n",
        "    StructField('customer_key', StringType(), True),\r\n",
        "    StructField('product_key', StringType(), True),\r\n",
        "    StructField('sales_price', DoubleType(), True),\r\n",
        "    StructField('sales_units', IntegerType(), True),\r\n",
        "    StructField('sales_month', StringType(), True),\r\n",
        "    StructField('sales_day', StringType(), True),\r\n",
        "    StructField('sales_year', IntegerType(), True),\r\n",
        "])\r\n",
        "\r\n",
        "\r\n",
        "productDF = spark.createDataFrame(data=productdim_data, schema = product_schema)\r\n",
        "storeDF = spark.createDataFrame(data=storedim_data, schema = store_schema)\r\n",
        "customerDF = spark.createDataFrame(data=customerdim_data, schema = customer_schema)\r\n",
        "salesDF = spark.createDataFrame(data=salesfact_data, schema = salesfact_schema)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Write the generated data out to the data lake"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "productDF.write.mode(\"overwrite\").format(\"parquet\").save(productdim_path)\r\n",
        "storeDF.write.mode(\"overwrite\").format(\"parquet\").save(storedim_path)\r\n",
        "customerDF.write.mode(\"overwrite\").format(\"parquet\").save(customerdim_path)\r\n",
        "salesDF.write.mode(\"overwrite\").format(\"parquet\").save(salesfact_path)"
      ]
    }
  ]
}